:py:mod:`torch_mist.train.mi_estimator`
=======================================

.. py:module:: torch_mist.train.mi_estimator


Module Contents
---------------


Functions
~~~~~~~~~

.. autoapisummary::

   torch_mist.train.mi_estimator._make_dataloaders
   torch_mist.train.mi_estimator._make_optimizer
   torch_mist.train.mi_estimator.train_mi_estimator



.. py:function:: _make_dataloaders(x: Optional[torch.Tensor] = None, y: Optional[torch.Tensor] = None, train_loader: Optional[Any] = None, valid_loader: Optional[Any] = None, valid_percentage: float = 0.1, batch_size: Optional[int] = None, num_workers: int = 8) -> Tuple[torch.utils.data.DataLoader, Optional[torch.utils.data.DataLoader]]


.. py:function:: _make_optimizer(estimator: torch_mist.estimators.base.MutualInformationEstimator, max_epochs: int, iterations_per_epoch: int, optimizer_class: Type[torch.optim.Optimizer] = Adam, optimizer_params: Optional[Dict[str, Any]] = None, lr_annealing: bool = False, warmup_percentage: float = 0.2) -> Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LRScheduler]


.. py:function:: train_mi_estimator(estimator: torch_mist.estimators.base.MutualInformationEstimator, x: Optional[torch.Tensor] = None, y: Optional[torch.Tensor] = None, train_loader: Optional[Any] = None, valid_loader: Optional[Any] = None, valid_percentage: float = 0.1, batch_size: Optional[int] = None, num_workers: int = 8, device: Union[torch.device, str] = torch.device('cpu'), max_epochs: int = 10, optimizer_class: Type[torch.optim.Optimizer] = Adam, optimizer_params: Optional[Dict[str, Any]] = None, lr_annealing: bool = False, warmup_percentage: float = 0.2, verbose: bool = True, return_log: bool = True, early_stopping: bool = True, patience: int = 3, delta: float = 0.001) -> Optional[pandas.DataFrame]


