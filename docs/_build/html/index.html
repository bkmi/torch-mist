<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mist - A PyTorch Mutual information Estimation toolkit &mdash; torch_mist  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Basic Usage" href="example.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #1a1a1a" >

          
          
          <a href="#">
            
              <img src="_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="example.html">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="example.html#advanced-usage">Advanced Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="autoapi/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #1a1a1a" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">torch_mist</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Mist - A PyTorch Mutual information Estimation toolkit</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mist-a-pytorch-mutual-information-estimation-toolkit">
<h1>Mist - A PyTorch Mutual information Estimation toolkit<a class="headerlink" href="#mist-a-pytorch-mutual-information-estimation-toolkit" title="Permalink to this heading"></a></h1>
<p><a class="reference external" href="https://arxiv.org/abs/2306.00608"><img alt="arXiv" src="https://img.shields.io/badge/arXiv-2306.00608-b31b1b.svg" /></a>
<a class="reference external" href="https://badge.fury.io/py/torch-mist"><img alt="PyPI version" src="https://badge.fury.io/py/torch-mist.svg" /></a>
<a class="reference external" href="https://codecov.io/gh/mfederici/torch-mist"><img alt="codecov" src="https://codecov.io/gh/mfederici/torch-mist/badge.svg" /></a>
<a class="reference external" href="https://torch-mist.readthedocs.io/en/latest/?badge=latest"><img alt="Documentation Status" src="https://readthedocs.org/projects/torch-mist/badge/?version=latest" /></a>
<a class="reference external" href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-green.svg" /></a></p>
<img src="docs/logo.png" onerror="this.onerror=null" width="200">
<p>Mutual Information Estimation toolkit based on pytorch. TO BE RELEASED SOON</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h2>
<p>The package can be installed via pip as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>torch_mist
</pre></div>
</div>
</section>
<section id="usage">
<h2>Usage<a class="headerlink" href="#usage" title="Permalink to this heading"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">torch_mist</span></code> package provides the basic functionalities for sample-based continuous mutual information estimation using modern
neural network architectures.</p>
<p>Here we provide a simple example of how to use the package to estimate mutual information between pairs
of observations using the MINE estimator <span class="xref myst">[2]</span>.
Consider the variables $x$ and $y$ as of shape <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">x_dim]</span></code>, <code class="docutils literal notranslate"><span class="pre">[N,</span> <span class="pre">y_dim]</span></code> respectively sampled from some joint distribution $p(x,y)$.
Mutual information can be estimated directly using the <code class="docutils literal notranslate"><span class="pre">estimate_mi</span></code> utility function that takes care of fitting the estimator’s parameters and evaluating mutual information.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_mist</span> <span class="kn">import</span> <span class="n">estimate_mi</span>

<span class="n">estimated_mi</span> <span class="o">=</span> <span class="n">estimate_mi</span><span class="p">(</span>
    
    <span class="c1"># Mutual Information estimator</span>
    <span class="n">estimator_name</span><span class="o">=</span><span class="s1">&#39;mine&#39;</span><span class="p">,</span>      <span class="c1"># Use MINE</span>
    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>       <span class="c1"># Hidden dimensions of the neural network</span>
    <span class="n">neg_samples</span><span class="o">=</span> <span class="mi">16</span><span class="p">,</span>            <span class="c1"># Number of negative examples </span>
    <span class="n">critic_type</span><span class="o">=</span><span class="s1">&#39;joint&#39;</span><span class="p">,</span>        <span class="c1"># Joint neural network for estimation</span>
    
    <span class="c1"># Data</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>                        <span class="c1"># The values for x</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>                        <span class="c1"># The values for y</span>
    
    <span class="c1"># Training</span>
    <span class="n">train_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>        <span class="c1"># The batch size used for training</span>
    <span class="n">evaluation_batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>  <span class="c1"># The batch size used for evaluation</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>              <span class="c1"># The maximum number of epochs</span>
    <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cpu&#39;</span><span class="p">,</span>               <span class="c1"># The torch device used for training</span>
    
    <span class="c1"># Flags to return the training log and estimator other than the estimation</span>
    <span class="n">return_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>           <span class="c1"># Return the training log</span>
    <span class="n">return_estimator</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>     <span class="c1"># Return the trained estimator</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>               <span class="c1"># Verbose output for the estimation procedure</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mutual information estimated value: </span><span class="si">{</span><span class="n">estimated_mi</span><span class="si">}</span><span class="s2"> nats&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Additional flags that can be used to customize the estimators, training and evaluation procedure are included in the documentation.</p>
<p>Alternatively, it is possible to manually instantiate, train and evaluate the mutual information estimators.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_mist.estimators</span> <span class="kn">import</span> <span class="n">mine</span>
<span class="kn">from</span> <span class="nn">torch_mist.train</span> <span class="kn">import</span> <span class="n">train_mi_estimator</span>
<span class="kn">from</span> <span class="nn">torch_mist.utils</span> <span class="kn">import</span> <span class="n">evaluate_mi</span>


<span class="c1"># This code performs the same procedure as the previous example</span>

<span class="c1"># Instantiate the mutual information estimator</span>
<span class="n">estimator</span> <span class="o">=</span> <span class="n">mine</span><span class="p">(</span>
    <span class="n">x_dim</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">y_dim</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">neg_samples</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">critic_type</span><span class="o">=</span><span class="s1">&#39;joint&#39;</span>
<span class="p">)</span>

<span class="c1"># Train it on the given samples</span>
<span class="n">train_log</span> <span class="o">=</span> <span class="n">train_mi_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">return_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1"># Evaluate the estimator on the entirety of the data</span>
<span class="n">estimated_mi</span> <span class="o">=</span> <span class="n">evaluate_mi</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Please refer to the <a class="reference external" href="https://torch-mist.readthedocs.io/en/latest/">documentation</a> for a detailed description of the package and its usage.</p>
<section id="estimators">
<h3>Estimators<a class="headerlink" href="#estimators" title="Permalink to this heading"></a></h3>
<p>Each estimator implemented in the library is an instance of <code class="docutils literal notranslate"><span class="pre">MutualInformationEstimator</span></code> and can be instantiated
through a simplified utility functions or directly for the corresponding class:</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="c1">############################</span>
<span class="c1"># Simplified instantiation #</span>
<span class="c1">############################</span>
<span class="kn">from</span> <span class="nn">torch_mist.estimators</span> <span class="kn">import</span> <span class="n">mine</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">mine</span><span class="p">(</span>
    <span class="n">x_dim</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">y_dim</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">neg_samples</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">critic_type</span><span class="o">=</span><span class="s1">&#39;joint&#39;</span>
<span class="p">)</span>

<span class="c1">##########################</span>
<span class="c1"># Advanced instantiation #</span>
<span class="c1">##########################</span>
<span class="kn">from</span> <span class="nn">torch_mist.estimators</span> <span class="kn">import</span> <span class="n">MINE</span>
<span class="kn">from</span> <span class="nn">torch_mist.critic</span> <span class="kn">import</span> <span class="n">JointCritic</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># First we define the critic architecture</span>
<span class="n">critic</span> <span class="o">=</span> <span class="n">JointCritic</span><span class="p">(</span>                               <span class="c1"># Wrapper to concatenate the inputs x and y </span>
    <span class="n">joint_net</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>                        <span class="c1"># The neural network architectures that maps [x,y] to a scalar</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">32</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Then we pass it to the MINE constructor</span>
<span class="n">estimator</span> <span class="o">=</span> <span class="n">MINE</span><span class="p">(</span>
    <span class="n">critic</span><span class="o">=</span><span class="n">critic</span><span class="p">,</span>
    <span class="n">neg_samples</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Note that the simplified and advanced instantiation reported in the example above result in the same model.</p>
<p>The basic estimators implemented in this package are summarized in the following table:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Estimator</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Models</p></th>
<th class="head"><p>Hyperparameters</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>NWJ <span class="xref myst">[1]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-odd"><td><p>MINE  <span class="xref myst">[2]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$</p></td>
<td><p>M, $\gamma_{EMA}$</p></td>
</tr>
<tr class="row-even"><td><p>InfoNCE <span class="xref myst">[3]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-odd"><td><p>TUBA  <span class="xref myst">[4]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$, $b_\xi(x)$</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-even"><td><p>AlphaTUBA <span class="xref myst">[4]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$, $b_\xi(x)$</p></td>
<td><p>M, $\alpha$</p></td>
</tr>
<tr class="row-odd"><td><p>JS <span class="xref myst">[5]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-even"><td><p>SMILE <span class="xref myst">[6]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$</p></td>
<td><p>M, $\tau$</p></td>
</tr>
<tr class="row-odd"><td><p>FLO <span class="xref myst">[7]</span></p></td>
<td><p>Discriminative</p></td>
<td><p>$f_\phi(x,y)$, $b_\xi(x,y)$</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-even"><td><p>BA <span class="xref myst">[8]</span></p></td>
<td><p>Generative</p></td>
<td><p>$q_\theta(y|x)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>DoE <span class="xref myst">[9]</span></p></td>
<td><p>Generative</p></td>
<td><p>$q_\theta(y|x)$, $q_\psi(y)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>GM <span class="xref myst">[6]</span></p></td>
<td><p>Generative</p></td>
<td><p>$q_\theta(x,y)$, $q_\psi(x)$, $q_\psi(y)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>L1OUT <span class="xref myst">[4]</span> <span class="xref myst">[10]</span></p></td>
<td><p>Generative</p></td>
<td><p>$q_\theta(y|x)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>CLUB <span class="xref myst">[10]</span></p></td>
<td><p>Generative</p></td>
<td><p>$q_\theta(y|x)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-odd"><td><p>Discrete <span class="xref myst">[]</span></p></td>
<td><p>Generative (Discrete)</p></td>
<td><p>$Q(x)$, $Q(y)$</p></td>
<td><p>-</p></td>
</tr>
<tr class="row-even"><td><p>PQ <span class="xref myst">[11]</span></p></td>
<td><p>Generative (Discrete)</p></td>
<td><p>$Q(y)$, $q_\theta(Q(y)|x)$</p></td>
<td><p>-</p></td>
</tr>
</tbody>
</table>
<p>in which the following models are used:</p>
<ul class="simple">
<li><p>$f_\phi(x,y)$ is a <code class="docutils literal notranslate"><span class="pre">critic</span></code> neural network with parameters $\phi, which maps pairs of observations to a scalar value.
Critics can be either <code class="docutils literal notranslate"><span class="pre">joint</span></code> or <code class="docutils literal notranslate"><span class="pre">separable</span></code> depending on whether they parametrize function of both $x$ and $y$ directly,
or through the product of separate projection heads ( $f_\phi(x,y)=h_\phi(x)^T h_\phi(y)$ ) respectively.</p></li>
<li><p>$b_\xi(x)$ is a <code class="docutils literal notranslate"><span class="pre">baseline</span></code> neural network with parameters $\xi$, which maps observations (or paris of observations) to a scalar value.
When the baseline is a function of both $x$ and $y$ it is referred to as a <code class="docutils literal notranslate"><span class="pre">joint_baseline</span></code>.</p></li>
<li><p>$q_\theta(y|x)$ is a conditional variational distribution <code class="docutils literal notranslate"><span class="pre">q_Y_given_X</span></code> used to approximate $p(y|x)$ with parameters $\theta$.
Conditional distributions may have learnable parameters $\theta$ that are usually parametrized by a (conditional) normalizing flow.</p></li>
<li><p>$q_\psi(y)$ is a marginal variational distribution <code class="docutils literal notranslate"><span class="pre">q_Y</span></code> used to approximate $p(y)$ with parameters $\psi$.
Marginal distributions may have learnable parameters $\psi$ that are usually parametrized by a normalizing flow.</p></li>
<li><p>$q_\theta(x,y)$ is a joint variational distribution <code class="docutils literal notranslate"><span class="pre">q_XY</span></code> used to approximate $p(x,y)$ with parameters $\theta$.
Joint distributions may have learnable parameters $\theta$ that are usually parametrized by a normalizing flow.</p></li>
<li><p>$Q(x)$ and $Q(y)$ are <code class="docutils literal notranslate"><span class="pre">quantization</span></code> functions that map observations to a finite set of discrete values.</p></li>
</ul>
<p>And the following hyperparameters:</p>
<ul class="simple">
<li><p>$M \in [1, N]$ is the number of samples used to estimate the log-normalization constant for each element in the batch.</p></li>
<li><p>$\gamma_{EMA} \in (0,1]$ is the exponential moving average decay used to update the baseline in MINE.</p></li>
<li><p>$\alpha \in [0,1]$ is the weight of the baseline in AlphaTUBA (0 corresponds to InfoNCE, 1 to TUBA).</p></li>
<li><p>$\tau \in [0..]$ is used to define the interval $[-\tau,\tau]$ in which critic values are clipped in SMILE.</p></li>
</ul>
<section id="hybrid-estimators">
<h4>Hybrid estimators<a class="headerlink" href="#hybrid-estimators" title="Permalink to this heading"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">torch_mist</span></code> package allows to combine Generative and Discriminative estimators in a single hybrid estimators as proposed in <span class="xref myst">[11]</span><span class="xref myst">[12]</span>.
COMING SOON</p>
</section>
</section>
<section id="training-and-evaluation">
<h3>Training and Evaluation<a class="headerlink" href="#training-and-evaluation" title="Permalink to this heading"></a></h3>
<p>Most of the estimators included in this package are parametric and require a training procedure for accurate estimation.
The <code class="docutils literal notranslate"><span class="pre">train_mi_estimator</span></code> utility function supports either row data <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> as <code class="docutils literal notranslate"><span class="pre">numpy.array</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>.
Alternatively, it is possible to use a <code class="docutils literal notranslate"><span class="pre">torch.utils.DataLoader</span></code> that returns eiter batches of pairs <code class="docutils literal notranslate"><span class="pre">(batch_x,</span> <span class="pre">batch_y)</span></code>
or dictionaries of batches <code class="docutils literal notranslate"><span class="pre">{'x':</span> <span class="pre">batch_x,</span> <span class="pre">'y':</span> <span class="pre">batch_y}</span></code>, with <code class="docutils literal notranslate"><span class="pre">batch_x</span></code> of shape <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">...,</span> <span class="pre">x_dim]</span></code> and <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">...,</span> <span class="pre">y_dim]</span></code> respectively.</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch_mist.train</span> <span class="kn">import</span> <span class="n">train_mi_estimator</span>

<span class="c1">######################################</span>
<span class="c1"># Training using tensors for x and y #</span>
<span class="c1">######################################</span>
<span class="c1"># By default 10% of the data is used for cross-validation and early stopping</span>
<span class="n">train_log</span> <span class="o">=</span> <span class="n">train_mi_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">valid_percentage</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">return_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="c1">#############################</span>
<span class="c1"># Training with DataLoaders #</span>
<span class="c1">#############################</span>
<span class="kn">from</span> <span class="nn">torch_mist.utils.data</span> <span class="kn">import</span> <span class="n">SampleDataset</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">random_split</span>

<span class="c1"># We provide an utility to make the tensors into a torch.utils.data.Dataset object</span>
<span class="c1"># This can be replaced with any other Dataset object that may load the data from disk</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">SampleDataset</span><span class="p">(</span>
    <span class="n">samples</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;x&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Split into train and validation</span>
<span class="n">train_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">*</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">valid_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="n">train_size</span>
<span class="n">train_set</span><span class="p">,</span> <span class="n">valid_set</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_size</span><span class="p">,</span> <span class="n">valid_size</span><span class="p">])</span>

<span class="c1"># Instantiate the dataloaders</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">train_set</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span>
<span class="p">)</span>

<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">valid_set</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span>
<span class="p">)</span>

<span class="c1"># Train using the specified dataloaders</span>
<span class="c1"># Note that the validation set is optional but recommended </span>
<span class="c1"># to prevent overfitting.</span>

<span class="n">train_log</span> <span class="o">=</span> <span class="n">train_mi_estimator</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">estimator</span><span class="p">,</span>
    <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span>
    <span class="n">valid_loader</span><span class="o">=</span><span class="n">valid_loader</span><span class="p">,</span>
    <span class="n">return_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The two options result in the same training procedure, but we recommend using <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> for larger datasets.</p>
<p>Both <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> (or <code class="docutils literal notranslate"><span class="pre">np.array</span></code>) can be used for the <code class="docutils literal notranslate"><span class="pre">evaluate_mi</span></code> function.</p>
</section>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/0809.0853">[1] </a> Nguyen, XuanLong, Martin J. Wainwright, and Michael I. Jordan. “Estimating divergence functionals and the likelihood ratio by convex risk minimization.” IEEE Transactions on Information Theory 56.11 (2010): 5847-5861.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1801.04062">[2]</a> Belghazi, Mohamed Ishmael, et al. “Mutual information neural estimation.” International conference on machine learning. PMLR, 2018.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1807.03748">[3]</a> Oord, Aaron van den, Yazhe Li, and Oriol Vinyals. “Representation learning with contrastive predictive coding.” arXiv preprint arXiv:1807.03748 (2018).</p>
<p><a class="reference external" href="https://arxiv.org/abs/1905.06922">[4]</a>  Poole, Ben, et al. “On variational bounds of mutual information.” International Conference on Machine Learning. PMLR, 2019.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1808.06670">[5]</a> Hjelm, R. Devon, et al. “Learning deep representations by mutual information estimation and maximization.” arXiv preprint arXiv:1808.06670 (2018).</p>
<p><a class="reference external" href="https://arxiv.org/abs/1910.06222">[6]</a> Song, Jiaming, and Stefano Ermon. “Understanding the limitations of variational mutual information estimators.” arXiv preprint arXiv:1910.06222 (2019).</p>
<p><a class="reference external" href="https://arxiv.org/abs/2107.01131">[7]</a> Guo, Qing, et al. “Tight mutual information estimation with contrastive fenchel-legendre optimization.” Advances in Neural Information Processing Systems 35 (2022): 28319-28334.</p>
<p><a class="reference external" href="https://aivalley.com/Papers/MI_NIPS_final.pdf">[8]</a> Barber, David, and Felix Agakov. “The im algorithm: a variational approach to information maximization.” Advances in neural information processing systems 16.320 (2004): 201.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1811.04251">[9]</a> McAllester, David, and Karl Stratos. “Formal limitations on the measurement of mutual information.” International Conference on Artificial Intelligence and Statistics. PMLR, 2020.</p>
<p><a class="reference external" href="https://arxiv.org/abs/2006.12013">[10]</a> Cheng, Pengyu, et al. “Club: A contrastive log-ratio upper bound of mutual information.” International conference on machine learning. PMLR, 2020.</p>
<p><a class="reference external" href="https://arxiv.org/abs/2306.00608">[11]</a> Federici, Marco, David Ruhe, and Patrick Forré. “On the Effectiveness of Hybrid Mutual Information Estimation.” arXiv preprint arXiv:2306.00608 (2023).</p>
<p><a class="reference external" href="https://arxiv.org/abs/2303.06992">[12]</a> Brekelmans, Rob, et al. “Improving mutual information estimation with annealed and energy-based bounds.” arXiv preprint arXiv:2303.06992 (2023).</p>
</section>
</section>
<section id="contributing">
<h2>Contributing<a class="headerlink" href="#contributing" title="Permalink to this heading"></a></h2>
<p>Interested in contributing? Check out the contributing guidelines. Please note that this project is released with a Code of Conduct. By contributing to this project, you agree to abide by its terms.</p>
</section>
<section id="license">
<h2>License<a class="headerlink" href="#license" title="Permalink to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch_mist</span></code> was created by Marco Federici. It is licensed under the terms of the MIT license.</p>
</section>
<section id="credits">
<h2>Credits<a class="headerlink" href="#credits" title="Permalink to this heading"></a></h2>
<p><code class="docutils literal notranslate"><span class="pre">torch_mist</span></code> was created with <a class="reference external" href="https://cookiecutter.readthedocs.io/en/latest/"><code class="docutils literal notranslate"><span class="pre">cookiecutter</span></code></a> and the <code class="docutils literal notranslate"><span class="pre">py-pkgs-cookiecutter</span></code> <a class="reference external" href="https://github.com/py-pkgs/py-pkgs-cookiecutter">template</a>.</p>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="example.html" class="btn btn-neutral float-right" title="Basic Usage" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Marco Federici.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>