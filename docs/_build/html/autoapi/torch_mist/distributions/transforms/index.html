<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>torch_mist.distributions.transforms &mdash; torch_mist  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/graphviz.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="torch_mist.distributions.transforms.base" href="base/index.html" />
    <link rel="prev" title="torch_mist.distributions.parametrizations.map" href="../parametrizations/map/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #1a1a1a" >

          
          
          <a href="../../../../index.html">
            
              <img src="../../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../example.html">Simple example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../conduct.html">Code of Conduct</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../index.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../critic/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.critic</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../data/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.data</span></code></a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../estimators/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.estimators</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../nn/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.nn</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../quantization/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.quantization</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../utils/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.utils</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../index.html#package-contents">Package Contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #1a1a1a" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">torch_mist</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">API Reference</a></li>
          <li class="breadcrumb-item"><a href="../../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist</span></code></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions</span></code></a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/autoapi/torch_mist/distributions/transforms/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-torch_mist.distributions.transforms">
<span id="torch-mist-distributions-transforms"></span><h1><a class="reference internal" href="#module-torch_mist.distributions.transforms" title="torch_mist.distributions.transforms"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms</span></code></a><a class="headerlink" href="#module-torch_mist.distributions.transforms" title="Permalink to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="base/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms.base</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="linear/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms.linear</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="permute/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms.permute</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="split/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch_mist.distributions.transforms.split</span></code></a></li>
</ul>
</div>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this heading"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.DistributionModule" title="torch_mist.distributions.transforms.DistributionModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionModule</span></code></a></p></td>
<td><p>Distribution is the abstract base class for probability distributions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.ConditionalDistributionModule" title="torch_mist.distributions.transforms.ConditionalDistributionModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionalDistributionModule</span></code></a></p></td>
<td><p>Helper class that provides a standard way to create an ABC using</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.TransformedDistributionModule" title="torch_mist.distributions.transforms.TransformedDistributionModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TransformedDistributionModule</span></code></a></p></td>
<td><p>Distribution is the abstract base class for probability distributions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.ConditionalTransformedDistributionModule" title="torch_mist.distributions.transforms.ConditionalTransformedDistributionModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionalTransformedDistributionModule</span></code></a></p></td>
<td><p>Helper class that provides a standard way to create an ABC using</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.Linear" title="torch_mist.distributions.transforms.Linear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Linear</span></code></a></p></td>
<td><p>Abstract class for invertable transformations with computable log</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.ConditionalLinear" title="torch_mist.distributions.transforms.ConditionalLinear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionalLinear</span></code></a></p></td>
<td><p>Conditional transforms with learnable parameters such as normalizing flows should inherit from this class rather</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.SplitTransform" title="torch_mist.distributions.transforms.SplitTransform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitTransform</span></code></a></p></td>
<td><p>Transforms with learnable parameters such as normalizing flows should inherit from this class rather</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.Permute" title="torch_mist.distributions.transforms.Permute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Permute</span></code></a></p></td>
<td><p>A bijection that reorders the input dimensions, that is, multiplies the input by</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="linear/index.html#module-torch_mist.distributions.transforms.linear" title="torch_mist.distributions.transforms.linear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.conditional_linear" title="torch_mist.distributions.transforms.conditional_linear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conditional_linear</span></code></a>(input_dim, context_dim[, ...])</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#torch_mist.distributions.transforms.conditional_skip_linear" title="torch_mist.distributions.transforms.conditional_skip_linear"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conditional_skip_linear</span></code></a>(input_dim, context_dim[, ...])</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="permute/index.html#module-torch_mist.distributions.transforms.permute" title="torch_mist.distributions.transforms.permute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">permute</span></code></a></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.DistributionModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">DistributionModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">validate_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#DistributionModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.DistributionModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.distributions.Distribution</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Distribution is the abstract base class for probability distributions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.DistributionModule.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#DistributionModule.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.DistributionModule.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return repr(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalDistributionModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">ConditionalDistributionModule</span></span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#ConditionalDistributionModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalDistributionModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.ConditionalDistribution</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.TransformedDistributionModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">TransformedDistributionModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_dist</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.distributions.Distribution</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#TransformedDistributionModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.TransformedDistributionModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch_mist.distributions.transforms.DistributionModule" title="torch_mist.distributions.transforms.DistributionModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DistributionModule</span></code></a></p>
<p>Distribution is the abstract base class for probability distributions.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.TransformedDistributionModule.rsample">
<span class="sig-name descname"><span class="pre">rsample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sample_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.Size()</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#TransformedDistributionModule.rsample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.TransformedDistributionModule.rsample" title="Permalink to this definition"></a></dt>
<dd><p>Generates a sample_shape shaped reparameterized sample or sample_shape
shaped batch of reparameterized samples if the distribution parameters
are batched.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.TransformedDistributionModule.log_prob">
<span class="sig-name descname"><span class="pre">log_prob</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#TransformedDistributionModule.log_prob"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.TransformedDistributionModule.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log of the probability density/mass function evaluated at
<cite>value</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>value</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.TransformedDistributionModule.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#TransformedDistributionModule.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.TransformedDistributionModule.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return repr(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalTransformedDistributionModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">ConditionalTransformedDistributionModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">base_dist</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pyro.distributions.ConditionalDistribution</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.distributions.Distribution</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transforms</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pyro.distributions.ConditionalTransform</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">pyro.distributions.ConditionalTransform</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pyro.distributions.ConditionalTransform</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.distributions.Transform</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">None</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#ConditionalTransformedDistributionModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalTransformedDistributionModule" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.ConditionalTransformedDistribution</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.nn.Module</span></code></p>
<p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.condition">
<span class="sig-name descname"><span class="pre">condition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#ConditionalTransformedDistributionModule.condition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.condition" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.distributions.Distribution</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.clear_cache">
<span class="sig-name descname"><span class="pre">clear_cache</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#ConditionalTransformedDistributionModule.clear_cache"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.clear_cache" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/base.html#ConditionalTransformedDistributionModule.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalTransformedDistributionModule.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Return repr(self).</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">Linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#Linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Linear" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">ConditionedLinear</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.TransformModule</span></code></p>
<p>Abstract class for invertable transformations with computable log
det jacobians. They are primarily used in
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.TransformedDistribution</span></code>.</p>
<p>Caching is useful for transforms whose inverses are either expensive or
numerically unstable. Note that care must be taken with memoized values
since the autograd graph may be reversed. For example while the following
works with or without caching:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">t</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># x will receive gradients.</span>
</pre></div>
</div>
<p>However the following will error when caching due to dependency reversal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="p">[</span><span class="n">y</span><span class="p">])</span>  <span class="c1"># error because z is x</span>
</pre></div>
</div>
<p>Derived classes should implement one or both of <code class="xref py py-meth docutils literal notranslate"><span class="pre">_call()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_inverse()</span></code>. Derived classes that set <cite>bijective=True</cite> should also
implement <code class="xref py py-meth docutils literal notranslate"><span class="pre">log_abs_det_jacobian()</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>cache_size</strong> (<em>int</em>) – Size of cache. If zero, no caching is done. If one,
the latest single value is cached. Only 0 and 1 are supported.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear.domain">
<span class="sig-name descname"><span class="pre">domain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.Linear.domain" title="Permalink to this definition"></a></dt>
<dd><p>The constraint representing valid inputs to this transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear.codomain">
<span class="sig-name descname"><span class="pre">codomain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.Linear.codomain" title="Permalink to this definition"></a></dt>
<dd><p>The constraint representing valid outputs to this transform
which are inputs to the inverse transform.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear.bijective">
<span class="sig-name descname"><span class="pre">bijective</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.Linear.bijective" title="Permalink to this definition"></a></dt>
<dd><p>Whether this transform is bijective. A transform
<code class="docutils literal notranslate"><span class="pre">t</span></code> is bijective iff <code class="docutils literal notranslate"><span class="pre">t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">x</span></code> and
<code class="docutils literal notranslate"><span class="pre">t(t.inv(y))</span> <span class="pre">==</span> <span class="pre">y</span></code> for every <code class="docutils literal notranslate"><span class="pre">x</span></code> in the domain and <code class="docutils literal notranslate"><span class="pre">y</span></code> in
the codomain. Transforms that are not bijective should at least
maintain the weaker pseudoinverse properties
<code class="docutils literal notranslate"><span class="pre">t(t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">t(x)</span></code> and <code class="docutils literal notranslate"><span class="pre">t.inv(t(t.inv(y)))</span> <span class="pre">==</span> <span class="pre">t.inv(y)</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear.sign">
<span class="sig-name descname"><span class="pre">sign</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.Linear.sign" title="Permalink to this definition"></a></dt>
<dd><p>For bijective univariate transforms, this
should be +1 or -1 depending on whether transform is monotone
increasing or decreasing.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Linear._params">
<span class="sig-name descname"><span class="pre">_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#Linear._params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Linear._params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">ConditionalLinear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">net</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-06</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">skip_connection</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#ConditionalLinear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.ConditionalTransformModule</span></code></p>
<p>Conditional transforms with learnable parameters such as normalizing flows should inherit from this class rather
than <code class="xref py py-class docutils literal notranslate"><span class="pre">ConditionalTransform</span></code> so they are also a subclass of
<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> and inherit all the useful methods of that class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear.domain">
<span class="sig-name descname"><span class="pre">domain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear.domain" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear.codomain">
<span class="sig-name descname"><span class="pre">codomain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear.codomain" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear.bijective">
<span class="sig-name descname"><span class="pre">bijective</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear.bijective" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear._params">
<span class="sig-name descname"><span class="pre">_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#ConditionalLinear._params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear._params" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.ConditionalLinear.condition">
<span class="sig-name descname"><span class="pre">condition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">context</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#ConditionalLinear.condition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.ConditionalLinear.condition" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.distributions.Transform</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.linear">
<span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.linear" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.conditional_linear">
<span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">conditional_linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#conditional_linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.conditional_linear" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.conditional_skip_linear">
<span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">conditional_skip_linear</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">context_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_dims</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_loc</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">initial_scale</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/linear.html#conditional_skip_linear"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.conditional_skip_linear" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">SplitTransform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.TransformModule</span></code></p>
<p>Transforms with learnable parameters such as normalizing flows should inherit from this class rather
than <cite>Transform</cite> so they are also a subclass of <cite>nn.Module</cite> and inherit all the useful methods of that class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.domain">
<span class="sig-name descname"><span class="pre">domain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.domain" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.codomain">
<span class="sig-name descname"><span class="pre">codomain</span></span><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.codomain" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.dist">
<span class="sig-name descname"><span class="pre">dist</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform.dist"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.dist" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.add_dims">
<span class="sig-name descname"><span class="pre">add_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform.add_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.add_dims" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.remove_dims">
<span class="sig-name descname"><span class="pre">remove_dims</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform.remove_dims"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.remove_dims" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform._call">
<span class="sig-name descname"><span class="pre">_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform._call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform._call" title="Permalink to this definition"></a></dt>
<dd><p>Abstract method to compute forward transformation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform._inverse">
<span class="sig-name descname"><span class="pre">_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform._inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform._inverse" title="Permalink to this definition"></a></dt>
<dd><p>Abstract method to compute inverse transformation.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.SplitTransform.log_abs_det_jacobian">
<span class="sig-name descname"><span class="pre">log_abs_det_jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/split.html#SplitTransform.log_abs_det_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.SplitTransform.log_abs_det_jacobian" title="Permalink to this definition"></a></dt>
<dd><p>Computes the log det jacobian <cite>log |dy/dx|</cite> given input and output.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Permute">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">Permute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">permutation</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#Permute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Permute" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.transforms.Permute</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">pyro.distributions.TransformModule</span></code></p>
<p>A bijection that reorders the input dimensions, that is, multiplies the input by
a permutation matrix. This is useful in between
<code class="xref py py-class docutils literal notranslate"><span class="pre">AffineAutoregressive</span></code> transforms to
increase the flexibility of the resulting distribution and stabilize learning.
Whilst not being an autoregressive transform, the log absolute determinate of
the Jacobian is easily calculable as 0. Note that reordering the input dimension
between two layers of
<code class="xref py py-class docutils literal notranslate"><span class="pre">AffineAutoregressive</span></code> is not equivalent
to reordering the dimension inside the MADE networks that those IAFs use; using
a <code class="xref py py-class docutils literal notranslate"><span class="pre">Permute</span></code> transform results in a
distribution with more flexibility.</p>
<p>Example usage:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyro.nn</span> <span class="kn">import</span> <span class="n">AutoRegressiveNN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyro.distributions.transforms</span> <span class="kn">import</span> <span class="n">AffineAutoregressive</span><span class="p">,</span> <span class="n">Permute</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iaf1</span> <span class="o">=</span> <span class="n">AffineAutoregressive</span><span class="p">(</span><span class="n">AutoRegressiveNN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">40</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ff</span> <span class="o">=</span> <span class="n">Permute</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">iaf2</span> <span class="o">=</span> <span class="n">AffineAutoregressive</span><span class="p">(</span><span class="n">AutoRegressiveNN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">[</span><span class="mi">40</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flow_dist</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">base_dist</span><span class="p">,</span> <span class="p">[</span><span class="n">iaf1</span><span class="p">,</span> <span class="n">ff</span><span class="p">,</span> <span class="n">iaf2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">flow_dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>permutation</strong> (<em>torch.LongTensor</em>) – a permutation ordering that is applied to the inputs.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – the tensor dimension to permute. This value must be negative and
defines the event dim as <cite>abs(dim)</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Permute.update_device">
<span class="sig-name descname"><span class="pre">update_device</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#Permute.update_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Permute.update_device" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Permute._call">
<span class="sig-name descname"><span class="pre">_call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#Permute._call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Permute._call" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>torch.Tensor</em>) – the input into the bijection</p>
</dd>
</dl>
<p>Invokes the bijection x=&gt;y; in the prototypical context of a
<code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedDistribution</span></code> <cite>x</cite> is a sample from
the base distribution (or the output of a previous transform)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Permute._inverse">
<span class="sig-name descname"><span class="pre">_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#Permute._inverse"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Permute._inverse" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>y</strong> (<em>torch.Tensor</em>) – the output of the bijection</p>
</dd>
</dl>
<p>Inverts y =&gt; x.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.Permute.log_abs_det_jacobian">
<span class="sig-name descname"><span class="pre">log_abs_det_jacobian</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#Permute.log_abs_det_jacobian"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.Permute.log_abs_det_jacobian" title="Permalink to this definition"></a></dt>
<dd><p>Calculates the elementwise determinant of the log Jacobian, i.e.
log(abs([dy_0/dx_0, …, dy_{N-1}/dx_{N-1}])). Note that this type of
transform is not autoregressive, so the log Jacobian is not the sum of the
previous expression. However, it turns out it’s always 0 (since the
determinant is -1 or +1), and so returning a vector of zeros works.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="torch_mist.distributions.transforms.permute">
<span class="sig-prename descclassname"><span class="pre">torch_mist.distributions.transforms.</span></span><span class="sig-name descname"><span class="pre">permute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">permutation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../../_modules/torch_mist/distributions/transforms/permute.html#permute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch_mist.distributions.transforms.permute" title="Permalink to this definition"></a></dt>
<dd><p>A helper function to create a <code class="xref py py-class docutils literal notranslate"><span class="pre">Permute</span></code>
object for consistency with other helpers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dim</strong> (<em>int</em>) – Dimension(s) of input variable to permute. Note that when
<cite>dim &lt; -1</cite> this must be a tuple corresponding to the event shape.</p></li>
<li><p><strong>permutation</strong> (<em>torch.LongTensor</em>) – Torch tensor of integer indices representing permutation.
Defaults to a random permutation.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – the tensor dimension to permute. This value must be negative and
defines the event dim as <cite>abs(dim)</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../parametrizations/map/index.html" class="btn btn-neutral float-left" title="torch_mist.distributions.parametrizations.map" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="base/index.html" class="btn btn-neutral float-right" title="torch_mist.distributions.transforms.base" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Marco Federici.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>