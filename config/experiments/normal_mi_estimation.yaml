data:
  class_path: core.data.datamodule.SampledNormalMixture
  init_args:
    samples_per_epoch: 100000
    batch_size: 64
    num_workers: 8
    n_dim: 5

model:
  class_path: core.task.InfoMax
  init_args:
    mi_estimator:
      class_path: core.models.mi_estimator.NWJ
      init_args:
        x_dim: 5
        y_dim: 5
        hidden_dims: [256, 128]
    optimizer_class: torch.optim.AdamW
    optimizer_init_args:
      lr: 1e-3
    lr_scheduler_class: core.optim.lr_scheduler.WarmupScheduler
    lr_scheduler_init_args:
      warmup_steps: 10 #10*[100000/128]
      total_steps: 100 #100*[100000/128]
    lr_scheduler_params:
      frequency: 1
      interval: step


trainer:
  max_epochs: 100
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: core.callbacks.VarianceLogCallback
      init_args:
          key: ["mi/value", "mi/grad"]
