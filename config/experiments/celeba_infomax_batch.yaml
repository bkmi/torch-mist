data:
  class_path: core.data.datamodule.CelebABatchDataModule
  init_args:
    num_workers: 24
    batch_size: 32
    sample_same_attributes: True
    train_transforms:
      class_path: pl_bolts.models.self_supervised.simclr.SimCLRTrainDataTransform
      init_args:
        jitter_strength: 0.5
        input_height: 128
    val_transforms:
      class_path: pl_bolts.models.self_supervised.simclr.SimCLREvalDataTransform
      init_args:
        input_height: 128
    train_attributes: [ 1, 5, 9, 13, 17, 21, 25, 29, 33, 37 ]

model:
  class_path: core.task.InfoMax
  init_args:
    encoder_x:
      class_path: core.models.encoder.VisionTransformer # Just a wrapper for torchvision.models.vision_transformer
      init_args:
        image_size: 128
        patch_size: 16
        num_layers: 8
        num_heads: 8
        hidden_dim: 256
        mlp_dim: 512
        out_dim: 512 # This corresponds to the dimension of the representation
    encoder_y: same
    mi_estimator:
      class_path: core.models.mi_estimator.SimCLR
      init_args:
        x_dim: 512
        y_dim: 512
        hidden_dims: [512]
    optimizer_class: torch.optim.AdamW
    optimizer_init_args:
      lr: 1e-3
    lr_scheduler_class: core.optim.lr_scheduler.WarmupScheduler
    lr_scheduler_init_args:
      warmup_steps: 10 #10*162770/32
      total_steps: 100 #100*162770/32
    lr_scheduler_params:
      frequency: 1
      interval: step

trainer:
  max_epochs: 100
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: core.callbacks.VarianceLogCallback
      init_args:
          key: ["mi/value", "mi/grad"]
