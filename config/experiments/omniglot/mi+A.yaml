data:
  class_path: core.data.datamodule.MultiOmniglotDataModule
  init_args:
    n_images: 1
    num_workers: 24
    batch_size: 128

model:
  class_path: core.task.InfoMax
  init_args:
    encoder_x:
      class_path: core.models.encoder.OmniglotResNet
      init_args:
        n_images: 1
        out_dim: 128
    encoder_y: same
    mi_estimator:
      class_path: core.models.mi_estimator.NWJ
      init_args:
        x_dim: 128
        y_dim: 128
        hidden_dims: [512, 256]
        predictor:
          class_path: core.models.predictor.ConditionalCategoricalMLP
          init_args:
            y_dim: 128
            hidden_dims: [ 256 ]
            n_classes: 32 # Number of clusters
            a_dim: 1
    optimizer_class: torch.optim.Adam
    optimizer_init_args:
        lr: 1e-3
    lr_scheduler_class: core.optim.lr_scheduler.WarmupScheduler
    lr_scheduler_init_args:
      warmup_steps: 10 #10*[162770/64]
      total_steps: 100 #100*[162770/64]
    lr_scheduler_params:
      frequency: 1
      interval: step

trainer:
  max_epochs: 100
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
    - class_path: core.callbacks.VarianceLogCallback
      init_args:
          key: ["mi/value", "mi/grad", "mi/primal/value", "mi/primal/grad", "mi/dual/value", "mi/dual/grad"]
    - class_path: core.callbacks.ClusteringCallback
      init_args:
        epochs: 50
        key_to_encode: 'x'
        clustering:
          class_path: sklearn.cluster.KMeans
          init_args:
            n_clusters: 32
            n_init: 50



#lr_scheduler:
#  class_path: core.optim.lr_scheduler.SimCLRScheduler
#  init_args:
#    warmup_steps: 1
#    total_steps: 100
